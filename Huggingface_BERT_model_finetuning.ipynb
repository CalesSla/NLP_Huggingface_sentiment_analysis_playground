{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "234b20f9",
   "metadata": {},
   "source": [
    "## Huggingface BERT model finetuning with native Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee53e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3070, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import string\n",
    "import itertools\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import tensorflow_text as text\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import GlobalMaxPool1D, BatchNormalization, Dense, RNN, GRU, LSTM, TimeDistributed, Bidirectional, Activation, Embedding, Input, Conv1D, Dropout\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "from transformers import pipeline\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import TFDistilBertForSequenceClassification, TFTrainer, TFTrainingArguments\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Define mixed precision policy\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dbd0a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data imports\n",
    "with open('reviews.txt', 'r') as f:\n",
    "  reviews = f.read()\n",
    "with open('labels.txt', 'r') as f:\n",
    "  labels = f.read()\n",
    "  \n",
    "  \n",
    "reviews = reviews.split('\\n')\n",
    "labels = labels.split('\\n')\n",
    "labels = [1 if label == \"positive\" else 0 for label in labels]\n",
    "\n",
    "# reviews = reviews[:10000]\n",
    "# labels = labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea749f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   ',\n",
       " 'story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers . unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting . even those from the era should be turned off . the cryptic dialogue would make shakespeare seem easy to a third grader . on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond . future stars sally kirkland and frederic forrest can be seen briefly .  ',\n",
       " 'homelessness  or houselessness as george carlin stated  has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school  work  or vote for the matter . most people think of the homeless as just a lost cause while worrying about things such as racism  the war on iraq  pressuring kids to succeed  technology  the elections  inflation  or worrying if they  ll be next to end up on the streets .  br    br   but what if you were given a bet to live on the streets for a month without the luxuries you once had from a home  the entertainment sets  a bathroom  pictures on the wall  a computer  and everything you once treasure to see what it  s like to be homeless  that is goddard bolt  s lesson .  br    br   mel brooks  who directs  who stars as bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival  jeffery tambor  to see if he can live in the streets for thirty days without the luxuries if bolt succeeds  he can do what he wants with a future project of making more buildings . the bet  s on where bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can  t step off the sidewalk . he  s given the nickname pepto by a vagrant after it  s written on his forehead where bolt meets other characters including a woman by the name of molly  lesley ann warren  an ex  dancer who got divorce before losing her home  and her pals sailor  howard morris  and fumes  teddy wilson  who are already used to the streets . they  re survivors . bolt isn  t . he  s not used to reaching mutual agreements like he once did when being rich where it  s fight or flight  kill or be killed .  br    br   while the love connection between molly and bolt wasn  t necessary to plot  i found  life stinks  to be one of mel brooks  observant films where prior to being a comedy  it shows a tender side compared to his slapstick work such as blazing saddles  young frankenstein  or spaceballs for the matter  to show what it  s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don  t know what to do with their money . maybe they should give it to the homeless instead of using it like monopoly money .  br    br   or maybe this film will inspire you to help others .  ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97432b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['reviews', 'labels'],\n",
       "    num_rows: 25001\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.from_dict({'reviews': reviews, 'labels': labels})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d917772",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ad5145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6251 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = 'distilbert-base-uncased'\n",
    "batch_size = 16\n",
    "max_length = 300\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize_function(train_dataset):\n",
    "    return tokenizer(train_dataset['reviews'], padding='max_length', truncation=True, max_length = max_length)\n",
    "  \n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88d6fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_dataset['train']\n",
    "test_dataset = tokenized_dataset['test']\n",
    "\n",
    "train_dataset = train_dataset.remove_columns(['reviews']).with_format('tensorflow')\n",
    "test_dataset = test_dataset.remove_columns(['reviews']).with_format('tensorflow')\n",
    "\n",
    "train_features = {x: train_dataset[x] for x in tokenizer.model_input_names}\n",
    "train_set = tf.data.Dataset.from_tensor_slices((train_features, train_dataset['labels'])).shuffle(1000).batch(batch_size)\n",
    "\n",
    "test_features = {x: test_dataset[x] for x in tokenizer.model_input_names}\n",
    "test_set = tf.data.Dataset.from_tensor_slices((test_features, test_dataset['labels'])).shuffle(1000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96dadcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'vocab_layer_norm', 'vocab_projector', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_19', 'pre_classifier', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "model.compile(\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "  metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39496d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1172/1172 [==============================] - 163s 135ms/step - loss: 0.4067 - accuracy: 0.8143 - val_loss: 0.3392 - val_accuracy: 0.8557\n",
      "Epoch 2/3\n",
      "1172/1172 [==============================] - 166s 142ms/step - loss: 0.3735 - accuracy: 0.8324 - val_loss: 0.3849 - val_accuracy: 0.8197\n",
      "Epoch 3/3\n",
      "1172/1172 [==============================] - 129s 110ms/step - loss: 0.3597 - accuracy: 0.8439 - val_loss: 0.3335 - val_accuracy: 0.8565\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set,\n",
    "                   validation_data = test_set,\n",
    "                   epochs = 3,\n",
    "                   batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254e3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af1ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84b0fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "047779ca",
   "metadata": {},
   "source": [
    "## Fine tuning Huggigface BERT model with trainer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77e89c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews, labels, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a44da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d178e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(X_train, truncation = True, padding = True)\n",
    "test_encodings = tokenizer(X_test, truncation = True, padding = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83613f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b65576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification, TFTrainer, TFTrainingArguments\n",
    "\n",
    "training_args = TFTrainingArguments(\n",
    "  output_dir = './results',\n",
    "  num_train_epochs = 2,\n",
    "  per_device_eval_batch_size = 4,\n",
    "  per_device_train_batch_size = 4,\n",
    "  warmup_steps = 500,\n",
    "  weight_decay = 0.01,\n",
    "  logging_dir = './logs',\n",
    "  logging_steps = 10,\n",
    "  eval_steps = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with training_args.strategy.scope():\n",
    "  model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "  \n",
    "trainer = TFTrainer(\n",
    "  model = model,\n",
    "  args = training_args,\n",
    "  train_dataset = train_dataset,\n",
    "  eval_dataset = test_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bed370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ad209",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model accuracy: {}'.format(sum([tf.math.argmax(predictions[0], axis = -1).numpy().tolist()[i] == y_test[i] for i in range(len(y_test))]) / len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f2f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397995a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
